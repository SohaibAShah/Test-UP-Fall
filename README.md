Fall Detection using Multimodal Sensor and Image Data
This repository contains the codebase for a PhD research project focused on developing robust fall detection systems using multimodal data, specifically combining sensor readings and camera imagery. The project explores various machine learning and deep learning models to classify human activities, with a particular emphasis on identifying fall events.
Table of Contents
Introduction
Dataset
Data Preprocessing
Model Architectures
Multi-Layer Perceptron (MLP)
XGBoost
CatBoost
Convolutional Neural Network (CNN) - Camera 1
Convolutional Neural Network (CNN) - Camera 2
Concatenated CNN (Camera 1 & 2)
Concatenated CSV + Images (Camera 1 & 2)
Random Forest
Support Vector Machine (SVM)
k-Nearest Neighbors (k-NN)
Evaluation Metrics
Project Structure
How to Run the Project
Requirements
Future Work
1. Introduction
Falls are a significant health concern, particularly among the elderly, leading to injuries, reduced quality of life, and increased healthcare costs. This research project aims to develop and evaluate various machine learning and deep learning models for accurate and timely fall detection. By leveraging multimodal data from both wearable sensors and ambient cameras, the project seeks to build more robust and reliable detection systems compared to unimodal approaches.
The codebase is structured to allow for easy experimentation with different models and data modalities, providing a clear pipeline from raw data to trained model evaluation.
2. Dataset
The project utilizes the UP-Fall Dataset, a publicly available dataset specifically designed for fall detection research. It is a multimodal dataset containing:
Sensor Data (Imp_sensor.csv): Time-series data from multiple wearable sensors (e.g., accelerometers, gyroscopes, luminosity, infrared, brainwave signals). Each row represents a timestamped reading.
Camera Data (zipped image files): Video frames captured from two different camera perspectives (Camera 1 and Camera 2) during various activities, including fall events. These are provided as sequences of images within zip archives.
The dataset captures a variety of activities, including different types of falls and Activities of Daily Living (ADLs), enabling the training and evaluation of models on diverse human movements.
3. Data Preprocessing
The data_preprocessing.py script handles all necessary steps to prepare the raw dataset for model training.
Loading Data:
Sensor data is loaded from Imp_sensor.csv into a Pandas DataFrame.
Camera image data (and associated timestamps/labels) are loaded from pre-saved .npy files (which are generated by a prior data loading script, typically from the raw zipped camera files).
Sensor Data Cleaning:
Rows with any NaN (Not a Number) values are dropped.
Duplicate rows are removed to ensure unique samples.
Specific columns related to Infrared sensors are dropped, as per the original notebook's methodology.
The 'Time' column is set as the DataFrame index for easier lookup and synchronization.
Image Data Processing:
Images are loaded as grayscale (cv2.IMREAD_GRAYSCALE).
Images are resized to a default 32x32 resolution to standardize input dimensions for CNNs.
Specific problematic image paths (e.g., those causing NO SHAPE or Invalid image errors in the original notebook) are explicitly skipped.
Timestamps are extracted from image filenames and formatted for synchronization.
Data Synchronization:
A critical step involves synchronizing the sensor data and image data based on their timestamps. Only data points with matching timestamps across both modalities are retained for combined models. This is achieved by finding common timestamps between the sensor DataFrame index and the image filenames.
Label Handling:
The raw labels are extracted. A specific remapping is applied where class 20 is converted to 0 (this is a dataset-specific adjustment).
For Keras-based models (MLP, CNNs), labels are converted to a one-hot encoded format (e.g., [0, 0, 1, 0, 0] for class 2).
For scikit-learn and XGBoost/CatBoost models, labels remain in integer format.
Data Splitting:
The entire dataset is split into training, validation, and test sets using a 60%/20%/20% ratio.
stratify=y_csv (or stratify=labels) is used during splitting to ensure that each split (train, validation, test) has a proportional representation of all activity classes, which is crucial for balanced model training, especially with imbalanced datasets.
Data Scaling and Reshaping:
CSV Data: Sensor features are scaled using StandardScaler to normalize their range, which is beneficial for many machine learning algorithms (especially neural networks and SVMs).
Image Data: Pixel values are normalized to the range [0, 1] by dividing by 255.0. Images are also reshaped to (height, width, 1) to explicitly add a channel dimension, as required by TensorFlow's Conv2D layers for grayscale images.
4. Model Architectures
This project implements and evaluates a diverse set of machine learning and deep learning models, each tailored to different data types (CSV, Images, or combined).
Multi-Layer Perceptron (MLP)
Type: Deep Learning (Feedforward Neural Network)
Input: Scaled CSV sensor data.
Architecture (models/mlp_model.py):
Input Layer: Dense(2000, activation=relu)
Hidden Layer 1: BatchNormalization()
Hidden Layer 2: Dense(600, activation=relu)
Hidden Layer 3: BatchNormalization()
Regularization: Dropout(0.2)
Output Layer: Dense(12, activation=softmax)
Compilation:
Optimizer: Adam(learning_rate=0.001)
Loss: CategoricalCrossentropy
Metrics: CategoricalAccuracy, Precision, Recall, F1Score(average='weighted')
XGBoost
Type: Gradient Boosting (Ensemble Learning)
Input: Scaled CSV sensor data (integer labels).
Architecture (models/xgboost_model.py):
XGBClassifier with objective="multi:softprob" for multi-class classification.
learning_rate=0.5
n_estimators=60
random_state=42
eval_metric="mlogloss"
Includes early_stopping_rounds=5 during fitting for efficient training.
CatBoost
Type: Gradient Boosting (Ensemble Learning)
Input: Scaled CSV sensor data (integer labels).
Architecture (models/catboost_model.py):
CatBoostClassifier
n_estimators=500
random_seed=42
learning_rate=0.25
max_depth=12
loss_function='MultiClass'
Includes early_stopping_rounds=10 during fitting.
Convolutional Neural Network (CNN) - Camera 1
Type: Deep Learning (CNN)
Input: Reshaped and normalized Camera 1 image data (32x32x1).
Architecture (models/cnn_camera1_model.py):
Input Layer: Input(shape=(32, 32, 1))
Convolutional Block: Conv2D(16, (3,3), activation=relu), BatchNormalization(), MaxPooling2D((2,2))
Flatten Layer: Flatten()
Dense Layers: Dense(200, activation=relu), Dropout(0.2)
Output Layer: Dense(12, activation=softmax)
Compilation: Similar to MLP.
Convolutional Neural Network (CNN) - Camera 2
Type: Deep Learning (CNN)
Input: Reshaped and normalized Camera 2 image data (32x32x1).
Architecture (models/cnn_camera2_model.py):
Identical architecture to the Camera 1 CNN, but trained independently on Camera 2 data.
Compilation: Similar to MLP.
Concatenated CNN (Camera 1 & 2)
Type: Deep Learning (Multi-Input CNN)
Input: Two separate input streams: Reshaped and normalized Camera 1 images, and Reshaped and normalized Camera 2 images.
Architecture (models/cnn_concatenate_model.py):
Branch 1 (Camera 1):
Input: Input(shape=(32, 32, 1))
Conv Block: Conv2D(16, (3,3), activation=relu), MaxPooling2D((2,2)), BatchNormalization()
Flatten: Flatten()
Branch 2 (Camera 2):
Input: Input(shape=(32, 32, 1))
Conv Block: Conv2D(16, (3,3), activation=relu), MaxPooling2D((2,2)), BatchNormalization()
Flatten: Flatten()
Concatenation: Concatenate(axis=1) of flatten1 and flatten2.
Dense Layers: Dense(400, activation=relu), Dense(200, activation=relu), Dropout(0.2)
Output Layer: Dense(12, activation=softmax)
Compilation: Similar to MLP.
Concatenated CSV + Images (Camera 1 & 2)
Type: Deep Learning (Multi-Input Multimodal Model)
Input: Three separate input streams: Scaled CSV sensor data, Reshaped and normalized Camera 1 images, and Reshaped and normalized Camera 2 images.
Architecture (models/cnn_csv_img_concatenate_model.py):
Branch 1 (CSV Data):
Input: Input(shape=(num_csv_features, 1)) (1D CNN for time-series-like data)
Conv Block: Conv1D(10, kernel_size=3, activation=relu), MaxPooling1D(pool_size=2), BatchNormalization()
Flatten: Flatten()
Branch 2 (Camera 1):
Input: Input(shape=(32, 32, 1))
Conv Block: Conv2D(16, (3,3), activation=relu), MaxPooling2D((2,2)), BatchNormalization()
Flatten: Flatten()
Branch 3 (Camera 2):
Input: Input(shape=(32, 32, 1))
Conv Block: Conv2D(16, (3,3), activation=relu), MaxPooling2D((2,2)), BatchNormalization()
Flatten: Flatten()
Concatenation: Concatenate(axis=1) of flat1, flat2, and flat3.
Dense Layers: Dense(600, activation=relu), Dense(1200, activation=relu), Dropout(0.2)
Output Layer: Dense(12, activation=softmax)
Compilation: Similar to MLP.
Random Forest
Type: Ensemble Learning (Bagging)
Input: Scaled CSV sensor data (integer labels).
Architecture (models/random_forest_model.py):
RandomForestClassifier
n_estimators=10
min_samples_split=2
min_samples_leaf=1
bootstrap=True
random_state=42
Support Vector Machine (SVM)
Type: Supervised Learning
Input: Scaled CSV sensor data (integer labels).
Architecture (models/svm_model.py):
svm.SVC
C=1 (regularization parameter)
kernel='rbf' (Radial Basis Function kernel)
gamma='auto'
shrinking=True
tol=0.001
random_state=42
k-Nearest Neighbors (k-NN)
Type: Non-parametric, Lazy Learning
Input: Scaled CSV sensor data (integer labels).
Architecture (models/knn_model.py):
KNeighborsClassifier
n_neighbors=5
leaf_size=30
metric='euclidean'
5. Evaluation Metrics
All models are evaluated using a comprehensive set of classification metrics to provide a holistic view of their performance:
Accuracy Score: The proportion of correctly classified instances among the total number of instances.
Precision Score (weighted): The ability of the classifier not to label as positive a sample that is negative. Weighted average accounts for class imbalance.
Recall Score (weighted): The ability of the classifier to find all the positive samples. Weighted average accounts for class imbalance.
F1 Score (weighted): The harmonic mean of precision and recall. It's a good measure for imbalanced datasets.
Balanced Accuracy Score: The average of recall obtained on each class. Useful for imbalanced datasets.
Confusion Matrix: A table that describes the performance of a classification model on a set of test data for which the true values are known.
6. Project Structure
TEST_UP_FALL/
├── UP-Fall Dataset/
│   ├── Imp_sensor.csv
│   ├── image_1.npy
│   ├── label_1.npy
│   ├── name_1.npy
│   ├── image_2.npy
│   ├── label_2.npy
│   └── name_2.npy
├── Saved Model/
│   └── Experiments/  # Trained models will be saved here
├── config.py           # Global configurations and constants
├── data_preprocessing.py # Scripts for loading, cleaning, and preparing data
├── utils.py            # Utility functions (e.g., set_seed, display_result, plotting)
├── main_training.py    # Main script to run model training and evaluation
└── models/             # Directory containing individual model definitions
    ├── __init__.py           # Makes 'models' a Python package
    ├── mlp_model.py
    ├── xgboost_model.py
    ├── catboost_model.py
    ├── cnn_camera1_model.py
    ├── cnn_camera2_model.py
    ├── cnn_concatenate_model.py
    ├── cnn_csv_img_concatenate_model.py
    ├── random_forest_model.py
    ├── svm_model.py
    └── knn_model.py



7. How to Run the Project
To run the training and evaluation pipeline, navigate to the your_project_root/ directory in your terminal and execute main_training.py.
You can specify which model(s) to train using the --model argument.
Run all models (default behavior):
python main_training.py



Run a specific model (e.g., MLP):
python main_training.py --model mlp



Run multiple specific models (e.g., XGBoost and Concatenated CNN):
python main_training.py --model xgboost cnn_concat



Available model choices:
all (runs all models)
mlp
xgboost
catboost
cnn_cam1
cnn_cam2
cnn_concat
cnn_csv_img_concat
random_forest
svm
knn
8. Requirements
To set up the environment and run the code, ensure you have Python 3.8+ installed. Then, install the required libraries:
pip install tensorflow tensorflow-addons scikit-learn pandas numpy opencv-python matplotlib xgboost catboost joblib



Note on tensorflow-addons: Ensure the tensorflow-addons version is compatible with your installed tensorflow version. Refer to the official TensorFlow Addons GitHub page for the compatibility matrix if you encounter import errors.
9. Future Work
Hyperparameter Optimization: Implement more systematic hyperparameter tuning (e.g., Grid Search, Random Search, Bayesian Optimization) for all models to maximize performance.
Cross-Validation: Integrate k-fold cross-validation for more robust model evaluation and to reduce bias from a single train/test split.
More Advanced Architectures: Explore more complex deep learning architectures, such as LSTMs or Transformers for sensor data, and more sophisticated CNNs (e.g., ResNet, Inception) for image data.
Real-time Inference: Develop a prototype for real-time fall detection using trained models.
Data Augmentation: Implement data augmentation techniques for image data to increase dataset diversity and improve model generalization.
Interpretability: Investigate methods to interpret model decisions, especially for deep learning models, to understand which features contribute most to fall detection.
